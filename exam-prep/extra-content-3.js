// CAIP-210 Study Content - Lessons 10-12
// Neural Networks and MLOps

// Lesson 10: Building Artificial Neural Networks
STUDY_CONTENT[10] = {
    name: "Lesson 10: Artificial Neural Networks",
    icon: "üß†",
    weight: "Focus Areas: MLP, CNN, RNN, Deep Learning",
    topics: [
        {
            title: "Multi-Layer Perceptrons (MLP)",
            concept: `MLPs s√£o redes neurais feedforward com camadas densamente conectadas:

üìä ARQUITETURA:
‚Ä¢ Camada de entrada: recebe features
‚Ä¢ Camadas ocultas: transforma√ß√µes n√£o-lineares
‚Ä¢ Camada de sa√≠da: previs√µes finais

üîó CONEX√ïES:
‚Ä¢ Cada neur√¥nio conectado a todos do layer seguinte
‚Ä¢ Pesos (weights) multiplicam inputs
‚Ä¢ Bias adicionado em cada neur√¥nio

‚ö° ATIVA√á√ïES:

ReLU (Rectified Linear Unit):
‚Ä¢ f(x) = max(0, x)
‚Ä¢ Mais usada em camadas ocultas
‚Ä¢ Resolve vanishing gradient

SIGMOID:
‚Ä¢ f(x) = 1 / (1 + e‚ÅªÀ£)
‚Ä¢ Output [0, 1]
‚Ä¢ Classifica√ß√£o bin√°ria

SOFTMAX:
‚Ä¢ Converte para probabilidades (soma = 1)
‚Ä¢ Classifica√ß√£o multi-classe

üîÑ TREINAMENTO:
‚Ä¢ Forward pass: calcular output
‚Ä¢ Loss: comparar com target
‚Ä¢ Backpropagation: calcular gradientes
‚Ä¢ Update: ajustar pesos

üìê REGULARIZA√á√ÉO:
‚Ä¢ Dropout: "desliga" neur√¥nios aleatoriamente
‚Ä¢ L1/L2: penalidade nos pesos
‚Ä¢ Early stopping: parar antes de overfit`,
            keyPoints: [
                "MLP = camadas densas (fully connected)",
                "ReLU √© ativa√ß√£o padr√£o para camadas ocultas",
                "Backpropagation calcula gradientes eficientemente",
                "Dropout √© regulariza√ß√£o mais efetiva em NNs",
                "Mais camadas/neur√¥nios = mais capacidade (e overfit)"
            ],
            example: `import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Arquitetura MLP
model = Sequential([
    Dense(64, activation='relu', input_shape=(n_features,)),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')  # classifica√ß√£o bin√°ria
])

# Compilar
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Resumo da arquitetura
model.summary()

# Callbacks
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

# Treinar
history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=100,
    batch_size=32,
    callbacks=[early_stop],
    verbose=1
)

# Plotar learning curves
import matplotlib.pyplot as plt
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()`,
            realCase: {
                title: "Sistemas de Recomenda√ß√£o do Spotify",
                description: "Spotify usa MLPs em seu sistema de recomenda√ß√£o, combinando features de usu√°rios e m√∫sicas para prever prefer√™ncias. Deep learning captura padr√µes complexos de gosto musical.",
                impact: "Discover Weekly usa embeddings de m√∫sicas treinados via MLPs"
            }
        },
        {
            title: "Convolutional Neural Networks (CNN)",
            concept: `CNNs s√£o especializadas em processar dados com estrutura espacial (imagens):

üìä CAMADAS PRINCIPAIS:

CONVOLUTIONAL:
‚Ä¢ Aplica filtros (kernels) √† imagem
‚Ä¢ Detecta features locais (bordas, texturas)
‚Ä¢ Par√¢metros compartilhados (eficiente)
‚Ä¢ Output: feature map

POOLING:
‚Ä¢ Reduz dimensionalidade espacial
‚Ä¢ Max pooling: pega valor m√°ximo
‚Ä¢ Average pooling: pega m√©dia
‚Ä¢ Torna representa√ß√£o mais robusta

FLATTEN:
‚Ä¢ Achata feature maps para vetor
‚Ä¢ Conecta a camadas densas

üìê HIPERPAR√ÇMETROS:
‚Ä¢ N√∫mero de filtros: quantas features detectar
‚Ä¢ Kernel size: tamanho do filtro (3x3, 5x5)
‚Ä¢ Stride: passo entre aplica√ß√µes
‚Ä¢ Padding: preservar dimens√µes ('same')

üèóÔ∏è ARQUITETURAS FAMOSAS:
‚Ä¢ LeNet: pioneira para d√≠gitos
‚Ä¢ AlexNet: breakthrough no ImageNet
‚Ä¢ VGG: camadas 3x3 profundas
‚Ä¢ ResNet: conex√µes residuais
‚Ä¢ EfficientNet: estado da arte`,
            keyPoints: [
                "Convolu√ß√µes detectam features espaciais locais",
                "Pooling reduz dimensionalidade e aumenta robustez",
                "Filtros iniciais: bordas, texturas; finais: objetos",
                "Transfer learning: usar redes pr√©-treinadas",
                "Data augmentation crucial para evitar overfit"
            ],
            example: `from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, 
                                       Dense, Dropout, BatchNormalization)
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Arquitetura CNN
model = Sequential([
    # Bloco 1
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64, 64, 3)),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    # Bloco 2
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    # Bloco 3
    Conv2D(128, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    # Classificador
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')  # 10 classes
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Data Augmentation (MUITO importante para imagens)
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2
)

# Transfer Learning com VGG16
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # congelar pesos

x = Flatten()(base_model.output)
x = Dense(256, activation='relu')(x)
output = Dense(num_classes, activation='softmax')(x)
model_transfer = Model(inputs=base_model.input, outputs=output)`,
            realCase: {
                title: "Diagn√≥stico de C√¢ncer de Pele",
                description: "Pesquisadores de Stanford treinaram CNNs para detectar c√¢ncer de pele com precis√£o compar√°vel a dermatologistas. O modelo analisa imagens de les√µes e classifica como benignas ou malignas.",
                impact: "CNNs atingiram n√≠vel de especialista em diagn√≥stico dermatol√≥gico"
            }
        },
        {
            title: "Recurrent Neural Networks (RNN)",
            concept: `RNNs processam sequ√™ncias mantendo mem√≥ria de passos anteriores:

üìä PROBLEMA COM SEQU√äNCIAS:
‚Ä¢ Texto, √°udio, s√©ries temporais
‚Ä¢ Ordem dos dados importa
‚Ä¢ Contexto de passos anteriores √© relevante

üîÑ ARQUITETURA RNN:
‚Ä¢ Estado oculto h_t mant√©m mem√≥ria
‚Ä¢ h_t = f(W_x √ó x_t + W_h √ó h_{t-1} + b)
‚Ä¢ Mesmo peso W compartilhado entre passos
‚Ä¢ Output pode ser a cada passo ou no final

‚ö†Ô∏è PROBLEMA:
‚Ä¢ Vanishing/exploding gradients
‚Ä¢ Dif√≠cil aprender depend√™ncias longas

üî∑ LSTM (Long Short-Term Memory):
‚Ä¢ C√©lula de mem√≥ria para longo prazo
‚Ä¢ Port√µes controlam fluxo de informa√ß√£o:
  - Forget gate: o que esquecer
  - Input gate: o que adicionar
  - Output gate: o que output

üî∂ GRU (Gated Recurrent Unit):
‚Ä¢ Vers√£o simplificada do LSTM
‚Ä¢ Menos par√¢metros
‚Ä¢ Performance similar

üìê APLICA√á√ïES:
‚Ä¢ NLP: tradu√ß√£o, sentiment analysis
‚Ä¢ S√©ries temporais: previs√£o
‚Ä¢ Gera√ß√£o de texto/m√∫sica`,
            keyPoints: [
                "RNNs mant√™m estado oculto entre passos",
                "LSTM resolve vanishing gradient com c√©lulas de mem√≥ria",
                "GRU √© alternativa mais simples ao LSTM",
                "Bidirectional: processa sequ√™ncia em ambas dire√ß√µes",
                "Transformers est√£o substituindo RNNs em NLP"
            ],
            example: `from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Bidirectional

# Para NLP: texto ‚Üí classes
model_nlp = Sequential([
    Embedding(vocab_size, 128, input_length=max_length),
    Bidirectional(LSTM(64, return_sequences=True)),
    Bidirectional(LSTM(32)),
    Dense(64, activation='relu'),
    Dense(num_classes, activation='softmax')
])

# Para S√©ries Temporais
# Formato input: (samples, timesteps, features)
model_ts = Sequential([
    LSTM(50, return_sequences=True, input_shape=(n_timesteps, n_features)),
    LSTM(50),
    Dense(1)  # prever pr√≥ximo valor
])

model_ts.compile(optimizer='adam', loss='mse')

# Preparar dados para LSTM (windowing)
def create_sequences(data, n_steps):
    X, y = [], []
    for i in range(len(data) - n_steps):
        X.append(data[i:(i + n_steps)])
        y.append(data[i + n_steps])
    return np.array(X), np.array(y)

n_steps = 10
X, y = create_sequences(time_series_data, n_steps)
X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, timesteps, features)

# GRU alternativa
model_gru = Sequential([
    GRU(50, input_shape=(n_timesteps, n_features)),
    Dense(1)
])`,
            realCase: {
                title: "Google Translate Neural Machine Translation",
                description: "Google usou arquiteturas sequence-to-sequence com LSTMs para tradu√ß√£o autom√°tica. O sistema codifica a frase fonte em um vetor e decodifica para o idioma alvo.",
                impact: "Reduziu erros de tradu√ß√£o em 60% comparado a sistemas baseados em regras"
            }
        }
    ]
};

// Lesson 11: Operationalizing ML Models
STUDY_CONTENT[11] = {
    name: "Lesson 11: Operationalizing ML Models",
    icon: "üöÄ",
    weight: "Focus Areas: Deployment, MLOps, Model Integration",
    topics: [
        {
            title: "Model Deployment",
            concept: `Deployar modelo = torn√°-lo dispon√≠vel para produ√ß√£o:

üìä FORMAS DE DEPLOY:

BATCH PREDICTION:
‚Ä¢ Processa dados em lotes peri√≥dicos
‚Ä¢ Ex: previs√µes noturnas
‚Ä¢ Mais simples, menos lat√™ncia cr√≠tica

REAL-TIME/ONLINE:
‚Ä¢ Previs√µes instant√¢neas via API
‚Ä¢ Lat√™ncia baixa √© crucial
‚Ä¢ Requer infraestrutura robusta

EDGE DEPLOYMENT:
‚Ä¢ Modelo roda no dispositivo
‚Ä¢ Sem conex√£o com servidor
‚Ä¢ Ex: apps mobile, IoT

üìê FORMATOS DE MODELO:

PICKLE/JOBLIB:
‚Ä¢ Serializa√ß√£o Python nativa
‚Ä¢ F√°cil mas dependente de vers√£o

ONNX:
‚Ä¢ Formato interoper√°vel
‚Ä¢ Funciona entre frameworks

TENSORFLOW SAVEDMODEL:
‚Ä¢ Formato TensorFlow nativo
‚Ä¢ Inclui grafo completo

TORCHSCRIPT:
‚Ä¢ Formato PyTorch otimizado
‚Ä¢ Para produ√ß√£o

üõ†Ô∏è FERRAMENTAS:
‚Ä¢ Flask/FastAPI: APIs simples
‚Ä¢ Docker: containeriza√ß√£o
‚Ä¢ Kubernetes: orquestra√ß√£o
‚Ä¢ MLflow: lifecycle management`,
            keyPoints: [
                "Batch: offline, lat√™ncia n√£o cr√≠tica",
                "Real-time: API, lat√™ncia baixa",
                "Edge: no dispositivo, sem servidor",
                "Docker containeriza modelo + depend√™ncias",
                "APIs REST s√£o padr√£o para servir modelos"
            ],
            example: `# Salvar modelo
import joblib
joblib.dump(model, 'model.pkl')

# FastAPI para servir modelo
from fastapi import FastAPI
from pydantic import BaseModel
import joblib

app = FastAPI()
model = joblib.load('model.pkl')

class PredictionRequest(BaseModel):
    features: list

@app.post("/predict")
def predict(request: PredictionRequest):
    prediction = model.predict([request.features])
    probability = model.predict_proba([request.features])
    return {
        "prediction": int(prediction[0]),
        "probability": float(probability[0].max())
    }

# Rodar: uvicorn app:app --host 0.0.0.0 --port 8000

# Dockerfile
"""
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
"""

# Testar API
import requests
response = requests.post(
    "http://localhost:8000/predict",
    json={"features": [1.5, 2.3, 4.1, 0.8]}
)
print(response.json())`,
            realCase: {
                title: "Uber ML Platform Michelangelo",
                description: "Uber construiu a plataforma Michelangelo para gerenciar todo o lifecycle de ML: feature engineering, treinamento, deploy e monitoramento. Suporta milhares de modelos em produ√ß√£o.",
                impact: "Democratizou ML na Uber, permitindo que n√£o-especialistas deployem modelos"
            }
        },
        {
            title: "MLOps Fundamentals",
            concept: `MLOps = DevOps aplicado a Machine Learning:

üìä PILARES:

CI/CD PARA ML:
‚Ä¢ CI: testar c√≥digo, dados e modelos
‚Ä¢ CD: deploy automatizado
‚Ä¢ CT (Continuous Training): retreinar modelos

VERSIONAMENTO:
‚Ä¢ C√≥digo: Git
‚Ä¢ Dados: DVC, Delta Lake
‚Ä¢ Modelos: MLflow, Weights & Biases
‚Ä¢ Experimentos: logs de hiperpar√¢metros

MONITORAMENTO:
‚Ä¢ Performance do modelo (accuracy, latency)
‚Ä¢ Data drift: mudan√ßa na distribui√ß√£o dos dados
‚Ä¢ Concept drift: mudan√ßa na rela√ß√£o input-output

üîÑ PIPELINE T√çPICO:
1. Feature Store ‚Üí features consistentes
2. Training Pipeline ‚Üí treinar modelo
3. Model Registry ‚Üí armazenar vers√µes
4. Serving ‚Üí API para previs√µes
5. Monitoring ‚Üí observar performance

üìê FERRAMENTAS:
‚Ä¢ MLflow: experiment tracking, registry
‚Ä¢ Kubeflow: pipelines em Kubernetes
‚Ä¢ Airflow: orquestra√ß√£o de workflows
‚Ä¢ Great Expectations: valida√ß√£o de dados
‚Ä¢ Evidently: monitoramento de drift`,
            keyPoints: [
                "MLOps = automa√ß√£o do lifecycle de ML",
                "Versionar c√≥digo, dados E modelos",
                "Continuous Training: retreinar periodicamente",
                "Monitorar drift: dados e performance",
                "Feature Stores garantem consist√™ncia"
            ],
            example: `# MLflow para tracking de experimentos
import mlflow
import mlflow.sklearn

# Iniciar experimento
mlflow.set_experiment("churn_prediction")

with mlflow.start_run():
    # Logar par√¢metros
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 10)
    
    # Treinar modelo
    model = RandomForestClassifier(n_estimators=100, max_depth=10)
    model.fit(X_train, y_train)
    
    # Logar m√©tricas
    accuracy = model.score(X_test, y_test)
    mlflow.log_metric("accuracy", accuracy)
    
    # Logar modelo
    mlflow.sklearn.log_model(model, "model")
    
    # Registrar no Model Registry
    mlflow.register_model(
        f"runs:/{mlflow.active_run().info.run_id}/model",
        "ChurnModel"
    )

# Carregar modelo do registry
model = mlflow.pyfunc.load_model("models:/ChurnModel/Production")

# DVC para versionamento de dados
"""
dvc init
dvc add data/training_data.csv
git add data/training_data.csv.dvc
git commit -m "Add training data"
dvc push
"""

# Great Expectations para valida√ß√£o
import great_expectations as ge

df_ge = ge.from_pandas(df)
df_ge.expect_column_values_to_be_between("age", min_value=0, max_value=120)
df_ge.expect_column_values_to_not_be_null("customer_id")`,
            realCase: {
                title: "Netflix Model Lifecycle",
                description: "Netflix retreina modelos de recomenda√ß√£o diariamente com novos dados de visualiza√ß√£o. MLOps automatiza todo o processo: coleta de dados, treinamento, valida√ß√£o, e deploy gradual (canary).",
                impact: "Modelos sempre atualizados com comportamento recente dos usu√°rios"
            }
        },
        {
            title: "Model Monitoring & Maintenance",
            concept: `Modelos em produ√ß√£o requerem monitoramento cont√≠nuo:

üìä O QUE MONITORAR:

PERFORMANCE:
‚Ä¢ Accuracy, F1, RMSE ao longo do tempo
‚Ä¢ Comparar com baseline/threshold
‚Ä¢ Alertar quando degradar

DATA DRIFT:
‚Ä¢ Distribui√ß√£o dos inputs mudou?
‚Ä¢ Estat√≠sticas: m√©dia, vari√¢ncia, distribui√ß√£o
‚Ä¢ Testes: KS, Chi-squared, PSI

CONCEPT DRIFT:
‚Ä¢ Rela√ß√£o input-output mudou?
‚Ä¢ Mesmo input ‚Üí outputs diferentes?
‚Ä¢ Harder to detect

OPERATIONAL:
‚Ä¢ Lat√™ncia de previs√£o
‚Ä¢ Throughput (requests/segundo)
‚Ä¢ Erros e exce√ß√µes

üîÑ ESTRAT√âGIAS DE RETREINAMENTO:

SCHEDULED:
‚Ä¢ Retreinar periodicamente (daily, weekly)
‚Ä¢ Simples mas pode ser desnecess√°rio

TRIGGERED:
‚Ä¢ Retreinar quando drift detectado
‚Ä¢ Mais eficiente
‚Ä¢ Requer bom monitoramento

ONLINE LEARNING:
‚Ä¢ Atualizar modelo continuamente
‚Ä¢ Para dados em streaming
‚Ä¢ Mais complexo

‚ö†Ô∏è ALERT FATIGUE:
‚Ä¢ Balancear sensibilidade de alertas
‚Ä¢ False positives cansam o time
‚Ä¢ Priorizar alertas cr√≠ticos`,
            keyPoints: [
                "Monitorar performance, data drift, concept drift",
                "Data drift: distribui√ß√£o de inputs mudou",
                "Concept drift: rela√ß√£o input-output mudou",
                "Retreinamento scheduled ou triggered",
                "Alertas bem calibrados evitam fatigue"
            ],
            example: `# Monitoramento com Evidently
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset, ClassificationPreset

# Comparar dados de refer√™ncia vs. atual
reference_data = df_train
current_data = df_production

# Relat√≥rio de Data Drift
drift_report = Report(metrics=[DataDriftPreset()])
drift_report.run(reference_data=reference_data, current_data=current_data)
drift_report.save_html("drift_report.html")

# Verificar drift programaticamente
drift_result = drift_report.as_dict()
if drift_result['metrics'][0]['result']['dataset_drift']:
    print("ALERTA: Data drift detectado!")
    # Trigger retreinamento
    
# Performance ao longo do tempo
from datetime import datetime, timedelta
import pandas as pd

# Simular log de previs√µes
predictions_log = pd.DataFrame({
    'timestamp': pd.date_range('2024-01-01', periods=1000, freq='H'),
    'prediction': np.random.binomial(1, 0.7, 1000),
    'actual': np.random.binomial(1, 0.7, 1000)
})

# Calcular accuracy por dia
predictions_log['date'] = predictions_log['timestamp'].dt.date
daily_accuracy = predictions_log.groupby('date').apply(
    lambda x: (x['prediction'] == x['actual']).mean()
)

# Alertar se accuracy cair abaixo de threshold
threshold = 0.65
if daily_accuracy.iloc[-1] < threshold:
    print(f"ALERTA: Accuracy caiu para {daily_accuracy.iloc[-1]:.2%}")

# PSI (Population Stability Index) para drift
def calculate_psi(expected, actual, bins=10):
    expected_percents = np.histogram(expected, bins)[0] / len(expected)
    actual_percents = np.histogram(actual, bins)[0] / len(actual)
    psi_values = (expected_percents - actual_percents) * np.log(expected_percents / actual_percents)
    return np.sum(psi_values)

psi = calculate_psi(reference_data['feature'], current_data['feature'])
if psi > 0.25:
    print(f"ALERTA: PSI = {psi:.3f} indica drift significativo")`,
            realCase: {
                title: "Monitoramento de Modelos de Fraude",
                description: "Bancos monitoram modelos de fraude continuamente porque fraudadores adaptam t√°ticas. Quando taxa de detec√ß√£o cai ou falsos positivos sobem, o modelo √© retreinado com novos padr√µes.",
                impact: "Adapta√ß√£o r√°pida a novas t√©cnicas de fraude protege milh√µes em transa√ß√µes"
            }
        }
    ]
};

// Lesson 12: Maintaining ML Operations
STUDY_CONTENT[12] = {
    name: "Lesson 12: Maintaining ML Operations",
    icon: "üîß",
    weight: "Focus Areas: Security, Production Maintenance, Best Practices",
    topics: [
        {
            title: "Securing ML Pipelines",
            concept: `Seguran√ßa √© cr√≠tica em sistemas de ML:

üîí √ÅREAS DE RISCO:

DADOS:
‚Ä¢ Dados sens√≠veis (PII) precisam prote√ß√£o
‚Ä¢ Anonimiza√ß√£o, pseudonimiza√ß√£o
‚Ä¢ Controle de acesso granular
‚Ä¢ Criptografia em repouso e tr√¢nsito

MODELOS:
‚Ä¢ Modelos s√£o IP (propriedade intelectual)
‚Ä¢ Ataques de extra√ß√£o de modelo
‚Ä¢ Backdoors em supply chain

PREVIS√ïES:
‚Ä¢ Outputs podem revelar dados de treino
‚Ä¢ Membership inference attacks
‚Ä¢ Adversarial examples

üìê PR√ÅTICAS DE SEGURAN√áA:

AUTHENTICATION:
‚Ä¢ Verificar identidade de usu√°rios/sistemas
‚Ä¢ API keys, OAuth, JWT

AUTHORIZATION:
‚Ä¢ Controlar o que cada identidade pode fazer
‚Ä¢ Principle of least privilege

AUDIT LOGGING:
‚Ä¢ Registrar acessos e opera√ß√µes
‚Ä¢ Detectar uso indevido
‚Ä¢ Compliance

PRIVACY BY DESIGN:
‚Ä¢ Considerar privacidade desde o in√≠cio
‚Ä¢ Data minimization
‚Ä¢ Differential privacy`,
            keyPoints: [
                "Proteger dados, modelos E previs√µes",
                "PII requer tratamento especial (GDPR, LGPD)",
                "Principle of least privilege para acessos",
                "Audit logs para compliance e detec√ß√£o",
                "Adversarial attacks: modelos podem ser enganados"
            ],
            example: `# Anonimiza√ß√£o de dados
import hashlib
from faker import Faker

def anonymize_pii(df):
    fake = Faker()
    
    # Hash de IDs (irrevers√≠vel)
    df['customer_id_hash'] = df['customer_id'].apply(
        lambda x: hashlib.sha256(str(x).encode()).hexdigest()
    )
    
    # Remover colunas originais
    df = df.drop(['customer_id', 'name', 'email', 'phone'], axis=1)
    
    # Generaliza√ß√£o de idade (k-anonimidade)
    df['age_group'] = pd.cut(df['age'], bins=[0, 25, 35, 45, 55, 100], 
                             labels=['18-25', '26-35', '36-45', '46-55', '55+'])
    df = df.drop('age', axis=1)
    
    return df

# Controle de acesso em API
from functools import wraps
from flask import request, jsonify

def require_api_key(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        api_key = request.headers.get('X-API-Key')
        if api_key not in VALID_API_KEYS:
            return jsonify({'error': 'Invalid API key'}), 401
        return f(*args, **kwargs)
    return decorated

# Audit logging
import logging
from datetime import datetime

audit_logger = logging.getLogger('audit')
audit_logger.setLevel(logging.INFO)

def log_prediction(user_id, input_data, prediction):
    audit_logger.info({
        'timestamp': datetime.utcnow().isoformat(),
        'user_id': user_id,
        'action': 'prediction',
        'input_hash': hashlib.md5(str(input_data).encode()).hexdigest(),
        'prediction': prediction
    })`,
            realCase: {
                title: "GDPR e Direito ao Esquecimento",
                description: "Sob GDPR, usu√°rios podem solicitar exclus√£o de seus dados. Se um modelo foi treinado com esses dados, pode ser necess√°rio retreinar sem eles (machine unlearning) para compliance.",
                impact: "Empresas precisam rastrear proveni√™ncia de dados em modelos"
            }
        },
        {
            title: "Models in Production",
            concept: `Manter modelos em produ√ß√£o requer pr√°ticas espec√≠ficas:

üìä DEPLOYMENT STRATEGIES:

CANARY RELEASE:
‚Ä¢ Deploy para pequena % de tr√°fego
‚Ä¢ Monitorar m√©tricas
‚Ä¢ Rollout gradual se ok

BLUE-GREEN:
‚Ä¢ Dois ambientes: atual (blue) e novo (green)
‚Ä¢ Switch instant√¢neo
‚Ä¢ Rollback f√°cil

A/B TESTING:
‚Ä¢ Comparar modelos lado a lado
‚Ä¢ Dividir tr√°fego entre vers√µes
‚Ä¢ Estatisticamente significante

SHADOW MODE:
‚Ä¢ Novo modelo roda em paralelo
‚Ä¢ N√£o afeta usu√°rios
‚Ä¢ Compara outputs

üîÑ ROLLBACK:
‚Ä¢ Sempre ter vers√£o anterior pronta
‚Ä¢ Automatizar rollback em caso de falha
‚Ä¢ Definir crit√©rios de rollback

üìê SCALING:

HORIZONTAL:
‚Ä¢ Mais inst√¢ncias do modelo
‚Ä¢ Load balancer distribui
‚Ä¢ Kubernetes autoscaling

VERTICAL:
‚Ä¢ M√°quina mais potente
‚Ä¢ Limitado por hardware

CACHING:
‚Ä¢ Cache de previs√µes frequentes
‚Ä¢ Reduz lat√™ncia e custo`,
            keyPoints: [
                "Canary release: deploy gradual com monitoramento",
                "A/B testing: comparar modelos estatisticamente",
                "Shadow mode: testar sem afetar produ√ß√£o",
                "Rollback deve ser automatizado e r√°pido",
                "Autoscaling adapta capacidade √† demanda"
            ],
            example: `# Kubernetes deployment com canary
"""
# Deployment principal (90% do tr√°fego)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-v1
spec:
  replicas: 9
  selector:
    matchLabels:
      app: ml-model
      version: v1
  template:
    metadata:
      labels:
        app: ml-model
        version: v1
    spec:
      containers:
      - name: model
        image: ml-model:v1
---
# Canary (10% do tr√°fego)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-v2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ml-model
      version: v2
  template:
    metadata:
      labels:
        app: ml-model
        version: v2
    spec:
      containers:
      - name: model
        image: ml-model:v2
"""

# A/B Testing em Python
import numpy as np

def ab_test_model(request, model_a, model_b, test_ratio=0.1):
    """Roteia requests entre modelos para A/B test"""
    if np.random.random() < test_ratio:
        # Grupo B (novo modelo)
        prediction = model_b.predict(request.features)
        log_ab_test('B', request.id, prediction)
    else:
        # Grupo A (modelo atual)
        prediction = model_a.predict(request.features)
        log_ab_test('A', request.id, prediction)
    return prediction

# Analisar resultados de A/B test
from scipy import stats

def analyze_ab_results(group_a_conversions, group_a_total,
                       group_b_conversions, group_b_total):
    rate_a = group_a_conversions / group_a_total
    rate_b = group_b_conversions / group_b_total
    
    # Chi-squared test
    contingency = [[group_a_conversions, group_a_total - group_a_conversions],
                   [group_b_conversions, group_b_total - group_b_conversions]]
    chi2, p_value = stats.chi2_contingency(contingency)[:2]
    
    print(f"Rate A: {rate_a:.2%}, Rate B: {rate_b:.2%}")
    print(f"Lift: {(rate_b - rate_a) / rate_a:.2%}")
    print(f"p-value: {p_value:.4f}")
    print(f"Significativo: {p_value < 0.05}")`,
            realCase: {
                title: "Facebook Continuous Deployment",
                description: "Facebook deploya mudan√ßas milhares de vezes por dia usando canary releases. Modelos de ML seguem o mesmo processo: deploy para 1% ‚Üí 10% ‚Üí 50% ‚Üí 100% com monitoramento autom√°tico.",
                impact: "Detec√ß√£o r√°pida de problemas antes de afetar todos os usu√°rios"
            }
        },
        {
            title: "Best Practices Summary",
            concept: `Resumo das melhores pr√°ticas para ML em produ√ß√£o:

üìä DESENVOLVIMENTO:

‚úÖ Versionar c√≥digo, dados E modelos
‚úÖ Reprodutibilidade: seeds, vers√µes fixas
‚úÖ Documentar decis√µes e raz√µes
‚úÖ Code review para ML code
‚úÖ Testes unit√°rios + integra√ß√£o

üìê TRAINING:

‚úÖ Never train on test data
‚úÖ Stratified splits para desbalanceados
‚úÖ Cross-validation para robustez
‚úÖ Early stopping para evitar overfit
‚úÖ Logar todos os experimentos

üöÄ DEPLOYMENT:

‚úÖ Containerizar (Docker)
‚úÖ Canary/gradual releases
‚úÖ Feature flags para rollback
‚úÖ Health checks automatizados
‚úÖ Documentar API (OpenAPI)

üìà MONITORING:

‚úÖ Dashboard de m√©tricas chave
‚úÖ Alertas para degrada√ß√£o
‚úÖ Detectar data/concept drift
‚úÖ Audit logs para compliance
‚úÖ SLAs definidos e monitorados

üîí SEGURAN√áA:

‚úÖ Criptografia de dados sens√≠veis
‚úÖ Least privilege access
‚úÖ Input validation e sanitization
‚úÖ Model versioning seguro
‚úÖ Incident response plan`,
            keyPoints: [
                "Reprodutibilidade √© fundamental: versionar tudo",
                "Automatizar o m√°ximo poss√≠vel (CI/CD/CT)",
                "Monitorar proativamente, n√£o reativamente",
                "Seguran√ßa desde o design, n√£o como addon",
                "Documenta√ß√£o √© parte do entreg√°vel"
            ],
            example: `# Checklist de produ√ß√£o
production_checklist = {
    'data': {
        'versioned': True,
        'validated': True,
        'pii_handled': True,
        'lineage_documented': True
    },
    'model': {
        'versioned': True,
        'registered': True,
        'metrics_logged': True,
        'reproducible': True
    },
    'deployment': {
        'containerized': True,
        'health_check': True,
        'rollback_ready': True,
        'scaled': True
    },
    'monitoring': {
        'performance_dashboard': True,
        'drift_detection': True,
        'alerts_configured': True,
        'logging_enabled': True
    },
    'security': {
        'auth_required': True,
        'data_encrypted': True,
        'audit_logging': True,
        'access_controlled': True
    }
}

# Verificar checklist
for category, items in production_checklist.items():
    missing = [k for k, v in items.items() if not v]
    if missing:
        print(f"‚ö†Ô∏è {category}: faltando {missing}")
    else:
        print(f"‚úÖ {category}: completo")

# Template de documenta√ß√£o
'''
# Model Card: [Nome do Modelo]

## Overview
- **Purpose**: [O que o modelo faz]
- **Owner**: [Equipe/pessoa respons√°vel]
- **Version**: [Vers√£o atual]

## Training
- **Data**: [Fonte, per√≠odo, tamanho]
- **Algorithm**: [Algoritmo usado]
- **Hyperparameters**: [Principais hiperpar√¢metros]

## Performance
- **Metrics**: [Accuracy, F1, etc.]
- **Fairness**: [An√°lise de vi√©s]
- **Limitations**: [Onde o modelo falha]

## Usage
- **Input**: [Formato esperado]
- **Output**: [Formato de sa√≠da]
- **API**: [Endpoint e documenta√ß√£o]

## Monitoring
- **SLAs**: [Lat√™ncia, uptime]
- **Alerts**: [Condi√ß√µes de alerta]
- **Retraining**: [Frequ√™ncia/trigger]
'''`,
            realCase: {
                title: "Google ML Best Practices",
                description: "Google publicou seu paper 'Rules of ML' com 43 regras pr√°ticas aprendidas em anos de ML em produ√ß√£o. Regra #1: 'Don't be afraid to launch without machine learning' - as vezes uma heur√≠stica simples √© melhor.",
                impact: "Guia refer√™ncia para engenheiros de ML em todo o mundo"
            }
        }
    ]
};
